{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Collection and Preprocessing (v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook handles the scraping of Google Play Store reviews for three bank apps, preprocessing the data, and saving it to a CSV file.\n",
    "\n",
    "**Instructions:**\n",
    "1. Update the `bank_apps` dictionary in the 'Configuration' section with the actual Google Play Store app IDs and desired names for your three target banks.\n",
    "2. Run all cells to perform scraping, preprocessing, and save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path to import custom modules\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    print(f\"Added {module_path} to sys.path\")\n",
    "\n",
    "from utils.scraper import PlayStoreScraper\n",
    "from utils.preprocessor import ReviewPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "**IMPORTANT:** Replace the placeholder `app_id` values with the actual Google Play Store IDs for the apps you want to scrape. You can find the app ID in the URL of the app's Play Store page (e.g., for Gmail, the URL is `https://play.google.com/store/apps/details?id=com.google.android.gm`, so the ID is `com.google.android.gm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define App IDs for the three banks and their names\n",
    "# PLEASE UPDATE THESE WITH ACTUAL APP IDs AND DESIRED NAMES\n",
    "bank_apps = {\n",
    "    'com.combanketh.mobilebanking': 'Commercial Bank of Ethiopia', # Example: 'com.cbe.mobile'\n",
    "    'com.boa.boaMobileBanking': 'Bank of Abysinnia', # Example: 'com.awashbank.mobile'\n",
    "    'com.dashen.dashensuperapp': 'Dashen Bank'  # Example: 'com.dashenbank.mobile'\n",
    "}\n",
    "\n",
    "TARGET_REVIEWS_PER_APP = 400\n",
    "LANG = 'en'  # Language for reviews\n",
    "COUNTRY = 'us' # Country for Play Store context (affects review availability)\n",
    "\n",
    "OUTPUT_CSV_PATH = '../data/google_play_reviews.csv'\n",
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Scraper and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = PlayStoreScraper()\n",
    "preprocessor = ReviewPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scrape and Preprocess Reviews for Each App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_dfs = []\n",
    "\n",
    "for app_id, bank_name in bank_apps.items():\n",
    "    print(f\"--- Processing: {bank_name} ({app_id}) ---\")\n",
    "    \n",
    "    # Scrape reviews\n",
    "    raw_reviews = scraper.get_reviews(\n",
    "        app_id=app_id, \n",
    "        app_name=bank_name, \n",
    "        lang=LANG, \n",
    "        country=COUNTRY, \n",
    "        count=TARGET_REVIEWS_PER_APP\n",
    "    )\n",
    "    \n",
    "    if not raw_reviews:\n",
    "        print(f\"No raw reviews fetched for {bank_name}. Skipping preprocessing.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Fetched {len(raw_reviews)} raw reviews for {bank_name}.\")\n",
    "    \n",
    "    # Preprocess reviews\n",
    "    processed_df_bank = preprocessor.preprocess_data(raw_reviews, bank_name)\n",
    "    \n",
    "    if not processed_df_bank.empty:\n",
    "        all_processed_dfs.append(processed_df_bank)\n",
    "        print(f\"Finished preprocessing for {bank_name}. {len(processed_df_bank)} reviews added.\")\n",
    "    else:\n",
    "        print(f\"No reviews remaining after preprocessing for {bank_name}.\")\n",
    "    print(\"------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combine Data and Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame() # Initialize an empty DataFrame\n",
    "\n",
    "if all_processed_dfs:\n",
    "    final_df = pd.concat(all_processed_dfs, ignore_index=True)\n",
    "    print(f\"Total reviews combined from all apps: {len(final_df)}\")\n",
    "    \n",
    "    # Ensure the data directory exists\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    \n",
    "    final_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "    print(f\"Combined dataset saved to: {OUTPUT_CSV_PATH}\")\n",
    "    print(\"\\nFirst 5 rows of the combined dataset:\")\n",
    "    print(final_df.head())\n",
    "else:\n",
    "    print(\"No data was processed or collected from any app. CSV file not saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KPIs Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not final_df.empty:\n",
    "    total_reviews_collected = len(final_df)\n",
    "    print(f\"Total reviews in final dataset: {total_reviews_collected}\")\n",
    "\n",
    "    # Missing data calculation\n",
    "    missing_data_summary = final_df.isnull().sum()\n",
    "    total_cells = final_df.size # Total number of cells (rows * columns)\n",
    "    total_missing_cells = missing_data_summary.sum()\n",
    "    missing_percentage = (total_missing_cells / total_cells) * 100 if total_cells > 0 else 0\n",
    "\n",
    "    print(\"\\nMissing data summary (per column):\")\n",
    "    print(missing_data_summary[missing_data_summary > 0]) # Show only columns with missing data\n",
    "    print(f\"\\nOverall missing data: {total_missing_cells} cells out of {total_cells} ({missing_percentage:.2f}%)\")\n",
    "\n",
    "    # KPI 1: 1,200+ reviews collected\n",
    "    target_total_reviews = 3 * TARGET_REVIEWS_PER_APP # Expected total\n",
    "    if total_reviews_collected >= target_total_reviews:\n",
    "        print(f\"\\nKPI Met: {total_reviews_collected} reviews collected (Target: {target_total_reviews}+). ({total_reviews_collected/target_total_reviews*100:.2f}% of target)\")\n",
    "    elif total_reviews_collected >= 1200: # Absolute minimum from brief\n",
    "         print(f\"\\nKPI Met (Minimum): {total_reviews_collected} reviews collected (Overall Target: 1200+). ({total_reviews_collected/1200*100:.2f}% of minimum target)\")\n",
    "    else:\n",
    "        print(f\"\\nKPI Not Met: Expected {target_total_reviews}+ (or min 1200) reviews, got {total_reviews_collected}.\")\n",
    "\n",
    "    # KPI 2: <5% missing data\n",
    "    if missing_percentage < 5:\n",
    "        print(\"KPI Met: Missing data is less than 5%.\")\n",
    "    else:\n",
    "        print(f\"KPI Not Met: Expected missing data < 5%, got {missing_percentage:.2f}%.\")\n",
    "else:\n",
    "    print(\"No data in the final DataFrame. KPIs cannot be checked.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
